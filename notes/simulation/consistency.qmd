---
title: "一致性・不偏性・効率性"
date: today
link-external-newwindow: true
---

　ここでは統計学を勉強する上でよく混同される一致性と不偏性について解説します。

## 一致性とは

　一致性はサンプルサイズが大きくなると、推定値が母数へ収束することを意味します。たとえば、$\mu = 0$、$\sigma = 100$の正規分布から独立的に抽出された$n$個の確率変数$X$があるとします。つまり、以下のような状況を考えます。

$$
X_1, X_2, X_3, ..., X_n \overset{\text{iid}}{\sim} N(0, 100).
$$

　ただし、ここでは$\mu = 0$、$\sigma = 100$を仮定しましたが、実際において私たちは$\mu$と$\sigma$の値は分かりません。たとえば、手元に男女100人の身長データがあっても、日本人全体の身長の平均値と分散は分かりません。したがって、私たちは手元にあるこの$X$のみを用いて、未知である母集団の特徴を推論する必要があります。手元の$X$から母集団における平均値（$\mu$）を推定する際によく使われるが平均値（$\bar{X}$）です。

　たとえば、$n = 5$の場合を考えてみましょう。

```{r}
set.seed(19861009) # 乱数のseedを指定
X1 <- rnorm(5, 0, 100) # N(0, 100)から乱数を5個抽出する
print(X1) # 抽出された乱数を出力する
mean(X1) # 抽出された乱数の平均値を出力する
```

　$n = 5$の場合、$\bar{X}$は`r mean(X1)`です。それでは$n = 100$ならどうでしょうか。

```{r}
X2 <- rnorm(100, 0, 100) # N(0, 100)から乱数を100個抽出する
print(X2) # 抽出された乱数を出力する
mean(X2) # 抽出された乱数の平均値を出力する
```

　$n = 100$の場合の$\bar{X}$は`r mean(X2)`ですね。最後に、$n = 10000$ならどうでしょうか。このサンプルを出力するのはあまりにも結果が長くなるので、ここでは平均値だけを出力します。

```{r}
X3 <- rnorm(10000, 0, 100) # N(0, 100)から乱数を1万個抽出する
mean(X3) # 抽出された乱数の平均値を出力する
```

　$n = 10000$の場合の$\bar{X}$は`r mean(X3)`ですね。このように$n$が大きくなると、$\bar{X}$は母集団の平均値（ここでは$\mu = 0$）へ近づきます。このようにサンプルサイズが大きくなると推定値が母数へ近づくことを「**一致性** (consistency)」と呼びます。この例だと、「標本の平均値（$\bar{X}$）は母集団の平均値（$\mu$）の一致推定量である」と言えます。これは$\bar{X} \overset{p}{\rightarrow} \mu$と表記されます。より一般的に書くと推定値$\hat{\theta}$が母数$\theta$の一致推定量である場合、$\hat{\theta} \overset{p}{\rightarrow} \theta$と表記します。

　この表記は大数の弱法則とも共通しますが、実際、一致性は大数の弱法則によって成り立ちます。

```{r}
#| message: false
library(tidyverse)

X_bar_vec <- rep(NA, 1000)     # 長さ1000の空ベクトルを作成
for (i in 1:1000) {            # iを1から1000へ増やしながら反復
  temp_vec <- rnorm(i, 0, 100) # N(0, 100)からi個の乱数を抽出し、temp_vecに格納
  # temp_vecの平均値をX_bar_vecのi番目要素として格納
  X_bar_vec[i] <- mean(temp_vec)
}

# 可視化
ggplot() +
  geom_line(aes(x = 1:1000, y = X_bar_vec)) +
  geom_hline(yintercept = 0, color = "red") +
  labs(x = "n", y = expression(hat(theta)))
```

　$n$を大きくすることによって$\bar{X}$が$\mu (=0)$へ近づくことが分かります。この$n$を無限にすると ($n \rightarrow \infty$)、$\bar{X} = \mu$になるでしょう。したがって、$\bar{X}$は$\mu$の一致推定量となります。


## 不偏性とは

　一致性と混同されやすい概念が「不偏性（unbiasedness）」です。これは推定値$\hat{\theta}$の**期待値**が母数$\theta$と一致することを意味します。数式で表すと$\mathbb{E}[\hat{\theta}] = \theta$であり、一致性と違って、サンプルサイズ（$n$）とは無関係な性質です。

　たとえば、$\mu = 0$、$\sigma = 100$の正規分布から独立的に5個の値を抽出します（$n = 5$）。そして、この5個の値の平均値（$\bar{X}$）を計算します。この作業を1万回繰り返したいと思います。

```{r}
#| cache: true
df <- tibble(Trial = 1:10000,
             X1    = rnorm(10000, 0, 100),
             X2    = rnorm(10000, 0, 100),
             X3    = rnorm(10000, 0, 100),
             X4    = rnorm(10000, 0, 100),
             X5    = rnorm(10000, 0, 100))

head(df)
```

　それでは$X_1$から$X_5$までの平均値を計算します。

```{r}
#| cache: true
df <- df %>%
  mutate(X_bar = (X1 + X2 + X3 + X4 + X5) / 5)

head(df)
```

　この$\bar{X}$の平均値（$\bar{\bar{X}}$）、つまり$\mathbb{E}[\bar{X}]$はどうでしょうか。厳密には$\mathbb{E}[\bar{X}]$ではありませんが、試行回数が無限回となると$\mathbb{E}[\bar{X}]$となります。試行回数1万は十分多いと考えられるので、期待値に近い結果が得られると考えられます。

```{r}
#| cache: true
mean(df$X_bar)
```

　$\mathbb{E}[\bar{X}]$は`r mean(df$X_bar)`であり、ほぼ0であることが分かります。この0が母数（$\mu$）であり、$\mathbb{E}[\bar{X}] = \mu$の関係が成り立つことが分かります。したがって、$\bar{X}$は$\mu$の不偏推定量となります。

　不偏推定量は複数存在することもあります。ここまで見てきました標本平均$\bar{X}$も$\mu$の不偏推定量の一つに過ぎません。たとえば、以下のような推定量を考えてみましょう。

$$
\begin{eqnarray}
  Y_1 & = X_3 \\
  Y_2 & = \frac{1}{9}(X_1 + 2 \cdot X_2 + 3 \cdot X_3 + 2 \cdot X_4 + X+5).
\end{eqnarray}
$$

```{r}
#| cache: true
df <- df %>%
  mutate(Y1 = X3,
         Y2 = (1/9) * (X1 + 2 * X2 + 3 * X3 + 2 * X4 + X5))

head(df)
```

　それでは$\mathbb{E}[Y_1]$と$\mathbb{E}[Y_2]$を計算してみましょう。

```{r}
mean(df$Y1)
mean(df$Y2)
```

　それぞれ`r mean(df$Y1)`と`r mean(df$Y2)`の結果が得られており、こちらも$\mu$に非常に近いことが分かります。標本平均以外にも母平均の不偏推定量がいくらでもあり得ることが分かります。

　しかし、なぜ$\mu$の不偏推定量として$\bar{X}$が使われているのでしょうか。それは$\bar{X}$が最も効率的な推定量であるからです。


---

## 効率性とは

　不偏推定量の中で一つ選ぶとしたら「効率性（efficiency）」というものを基準とします。同じ不偏推定量であれば、精度の高い推定量、つまり分散が小さい推定量がいいでしょう。この精度の良さが「効率性」です。他にも、「有効性」と呼ばれる場合もあります。

　効率性の最も良い推定量のことを有効推定量と呼びます。この効率性は簡単にいうと推定量の分散を意味します。これまで$\mu$の不偏推定量として$\bar{X}$、$Y_1$、$Y_2$を見てきました。これら3つの不偏推定量の効率性は$V[\bar{X}]$、$V[Y_1]$、$V[Y_2]$を用いて調べることが可能です。

```{r}
var(df$X_bar)
var(df$Y1)
var(df$Y2)
```

　それぞれの分散は`r var(df$X_bar)`、`r var(df$Y1)`、`r var(df$Y2)`であり、$V[\bar{X}]$が最も分散が小さい、つまり最も効率的な推定量であることが分かります。$\bar{X}$は一致推定量でありながら不偏推定量であり、そして最も効率的な$\mu$の推定量となります。

---

## 一致推定量=不偏推定量?

　先ほどの標本平均は一致推定量でありながら、不偏推定量でした。しかし、世の中には一致推定量でありながら、不偏推定量ではない推定量が存在します。その代表的な例が標本分散（$s^2$）です。標本分散（$s^2$）は母集団における分散（$\sigma^2$）の一致推定量ですが、不偏推定量ではありません。

　たとえば、$\mu = 0$、$\sigma = 100$の正規分布から独立的に1000万個の乱数を生成したとします。この場合、母分散（$\sigma^2$）は10000となります。そして、この1000万個の値の標本分散（$s^2$）と不偏分散（$\hat{\sigma}^2$）を計算します。ちなみに、Rの`var()`は不偏分散を計算するため、標本分散を求めるためには不偏分散に$\frac{n-1}{n}$を掛ける必要があります。

```{r}
X <- rnorm(10000000, 0, 100)
var(X) * ((length(X) - 1) / length(X)) # 標本分散
var(X) # 不偏分散
```

　どれも母分散に非常に近い値が得られており、$n$を無限にすると母分散に一致すると予想されます。したがって、$s^2 \overset{p}{\rightarrow} \sigma^2$、$\hat{\sigma}^2 \overset{p}{\rightarrow} \sigma^2$であり、どれも一致推定量であることが分かります。

```{r}
#| cache: true
df <- tibble(Trial = 1:10000,
             X1    = rnorm(10000, 0, 100),
             X2    = rnorm(10000, 0, 100),
             X3    = rnorm(10000, 0, 100),
             X4    = rnorm(10000, 0, 100),
             X5    = rnorm(10000, 0, 100))

df <- df %>%
  rowwise() %>% # 行単位の演算
  mutate(S_2         = var(c(X1, X2, X3, X4, X5)) * (4/5), # 各試行における標本分散
         Sigma_hat_2 = var(c(X1, X2, X3, X4, X5)))         # 各試行における不偏分散

head(df)
```

　それでは$s^2$と$\hat{\sigma}^2$の平均値（$\simeq$期待値）を計算してみましょう。

```{r}
mean(df$S_2) # 標本分散の期待値
mean(df$Sigma_hat_2) # 不偏分散の期待値
```

　標本分散の期待値は約8000で、母分散の$\frac{n-1}{n}$、つまり$\frac{4}{5}$となります。一方、不偏分散の場合期待値が母分散に非常に近いことが分かります。したがって、不偏分散は一致性と不偏性があり、標本分散は一致性のみあることが分かります。

　逆に不偏推定量でありながら一致推定量ではない推定量も存在します。たとえば、以下のような例を考えてみましょう。

1. $X_1, X_2, X_3, ..., X_n \overset{\text{iid}}{\sim} N(0, 100)$とする
2. $|X_i| = \max{(|X_1|, |X_2|, |X_3|, ..., |X_i|, ..., |X_n|)}$の場合、$\hat{\theta} = X_i$

　要するに、絶対値の最も高かった値を$\theta$の推定量（$\hat{\theta}$）として用いることを意味します。この場合、$\hat{\theta}$は一致推定量でしょうか。$n$を1から1000まで増やしながら確認してみましょう。

```{r}
#| cache: true
theta_hat_vec <- rep(NA, 1000) # 長さ1000の空ベクトルを作成
for (i in 1:1000) {            # iを1から1000へ増やしながら反復
  temp_vec <- rnorm(i, 0, 100) # N(0, 100)からi個の乱数を抽出し、temp_vecに格納
  # temp_vecの中で最も絶対値の高い値はtheta_hat_vecのi番目要素として格納
  theta_hat_vec[i] <- temp_vec[abs(temp_vec) == max(abs(temp_vec))]
}

# 可視化
ggplot() +
  geom_line(aes(x = 1:1000, y = theta_hat_vec)) +
  geom_hline(yintercept = 0, color = "red") +
  labs(x = "n", y = expression(hat(theta)))
```

　このように$n$をいくら増やしても$\hat{\theta}$は母数である0へ収束しないことが分かります。つまり、この推定量は一致推定量ではありません。それでは、この推定量は不偏推定量でしょうか。ここでは話を単純にするために$n = 3$の例を考えてみましょう。不偏性はサンプルサイズ（$n$）と無関係ですので、これでも問題ないでしょう。試行数は100万とします。

```{r}
#| cache: true
# シミュレーション用のデータを作成
df <- tibble(Trial = paste0("Trial", 1:1000000),
             X1    = rnorm(1000000, 0, 100),
             X2    = rnorm(1000000, 0, 100),
             X3    = rnorm(1000000, 0, 100))

df <- df %>% 
  # X1, X2, X3の中で絶対値の最も高い値をTheta_Hatとする
  mutate(Theta_Hat = case_when(abs(X1) > abs(X2) & abs(X2) > abs(X3) ~ X1,
                               abs(X2) > abs(X3)                     ~ X2,
                               TRUE                                  ~ X3)) 

head(df) # dfの中身を確認する
```

```{r}
# dfのTheta_Hat列の期待値（平均値）を計算する。
mean(df$Theta_Hat)
```

　非常に0に近い結果が得られており、これはほぼ$\mu$と同じ値となります。施行数が無限回になると、$\mathbb{E}[\hat{\theta}]$は$\mu$と一致していくだろうと考えられます。

　我々が教科書でよく見る推定量は一般的に一致性と不偏性を同時に満たす推定量が多いでしょう。しかし、例外も常に存在します。標本分散もその一つの例です。他にも、最尤推定法から得られた分散の推定量は一致推定量ではあるものの、不偏推定量ではないことが知られています。