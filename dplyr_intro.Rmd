---
title: "dplyr入門 (新版)"
date: '2020-06-28'
categories: []
tags: ["統計学", "R", "データハンドリング"]
editor_options: 
  chunk_output_type: console
---

## はじめに

* 以下の内容は現在執筆中の内容の一部となります。
    * Song Jaehyun・矢内勇生『私たちのR: あなたのために書いたわけじゃない (仮)』(E-book)
    * したがって、いきなり**オブジェクト**、**関数**、**引数**といった馴染みのない概念が出てきます。これらの概念に馴染みのない方は、予め「[Rプログラミング入門の入門](../rprogramming/)」をご一読ください。
* 2020年6月に公開されましたdplyr 1.0.0に対応しております。
* 2016年5月に作成しました旧版は[ここ](../dplyr_intro_old/)から閲覧できます。
* 実習データは[ここ](../Data/Ramen.csv)からダウンロード可能です。

---

## パッケージと実習用データの読み込み

パッケージは`dplyr`でも、`tidyverse`でもどれでも構いません。ここではデータをtibble型として読み込むため、`tidyverse`を読み込んでおきます。

```{r, attr.source='.numberLines'}
library(tidyverse)
```

それでは今回の実習用データを読み込みましょう。[Ramen.csv](../Data/Ramen.csv)には「[ぐるなび](https://www.gnavi.co.jp)」から取得したラーメン屋6292店舗の情報が入っています。具体的には東京、神奈川、千葉、埼玉、大阪、京都、兵庫、奈良、和歌山それぞれ都府県にあるラーメン屋の中から最大1000店舗の情報を抽出したものです。東京都は、ぐるなびに登録したラーメン屋が3000店舗以上ですが、1000店舗の基準はぐるなびの「おすすめ」の順で上位1000店舗となります。また、店側またはぐるなびが登録したカテゴリを基準に抽出したため、実際はラーメン屋ではないにもかかわらずラーメン屋としてデータ内に含まれている可能性があります。

まず、このデータを読み込み、`df`という名付けます。R内蔵関数である`read.csv()`を使ってデータを読み込んでも以下の内容を実習するにあたって全く問題はございません。`read.csv()`から読み込まれたデータのクラスはデータフレーム、`read_csv()`の場合はtibbleです。tibbleはデータフレームの拡張版であり、データフレームで可能な操作は全てtibbleにおいても可能です。ここではtibbleを使いますが、こちらの方が、結果が読みやすく出力されるからです。

```{r, attr.source='.numberLines'}
# ファイルのパスは適宜修正してください
df <- read_csv("Data/Ramen.csv")
```

本サンプルデータはUTF-8で保存されており、文字化けが生じる場合、以下のように対処してください。

```{r, eval = FALSE}
# readrパッケージのread_csv()を使う場合
df <- read_csv("Data/Ramen.csv", locale = locale(encoding = "utf8"))

# R内臓のread.csv()を使う場合
df <- read_csv("Data/Ramen.csv", fileEncoding = "utf8")
```


データの中身を確認してみましょう。

```{r, attr.source='.numberLines'}
df
```

1行目の`# A tibble: 6,292 x 14`から、ケース数 (店舗数)は6292、変数は14個あることが分かります。各変数の詳細は以下の通りです。

```{r, attr.source='.numberLines', echo = FALSE, message = FALSE}
library(knitr)
library(kableExtra)

data.frame(変数名 = c("`ID`", "`Name`", 
                   "`Pref`", "`Zipcode`", "`Latitude`", "`Longitude`",
                   "`Line`", "`Station`", "`Walk`", "`Bus`", "`Car`",
                   "`Budget`", "`ScoreN`", "`Score`"),
              説明 = c("店舗ID",
                     "店舗名",
                     "店舗の所在地 (都府県)",
                     "店舗の郵便番号",
                     "緯度",
                     "経度",
                     "最寄りの駅の路線",
                     "最寄りの駅",
                     "最寄りの駅からの距離 (徒歩; 分)",
                     "最寄りの駅からの距離 (バス; 分)",
                     "最寄りの駅からの距離 (車; 分)",
                     "平均予算 (円)",
                     "口コミの数",
                     "口コミ評価の平均値")) %>%
  kable() %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed",
                                        "responsive"),
                  full_width = FALSE)
```

それではここからは`df`を用いた`dplyr`の様々な機能を紹介していきます。

---

## パイプ演算子

`dplyr`パッケージを利用する前にパイプ演算子について説明します。パイプ演算子は`dplyr`に含まれている演算子ではなく、`magrittr`という別のパッケージから提供される演算子ですが、`tidyverse`パッケージを読み込むと自動的に読み込まれます。パイプ演算子は`x %>% y()`のような書き方となりますが、これは「`x`を`y()`の第一引数として渡す」ことを意味します。`x`の部分はベクトルやデータフレームのようなオブジェクトでも、関数でも構いません。なぜなら、関数から得られた結果もまたベクトルやデータフレームといったものになるからです。つまり、`x() %>% y()`という使い方も可能です。そして、パイプは無限に繋ぐこともできます。「データ`df`を関数`x()`で処理をし、その結果をまた関数`y()`で処理する」ことは、パイプを使うと`df %>% x() %>% y()`のような書き方となります。

たとえば、「`paste(3, "+", 5, "=", 8)`を実行し、その結果を`rep()`関数を使って3回複製し、それを`print()`を使って出力する」コードを考えてみましょう。方法としては2つ考えられます。まずは、それぞれの処理を別途のオブジェクトに格納する方法です。そして二つ目は関数の中に関数を使う方法です。

```{r, attr.source='.numberLines'}
# 方法1: 一関数一オブジェクト
Result1 <- paste(3, "+", 5, "=", 8)
Result2 <- rep(Result1, 3)
print(Result2)

# 方法2: 関数の中に関数の中に関数
print(rep(paste(3, "+", 5, "=", 8), 3))
```

どれも結果は同じです。コードを書く手間を考えれば、後者の方が楽かも知れませんが、可読性があまりよくありません。一方、前者は可読性は良いものの、コードも長くなり、オブジェクトを2つも作ってしまうのでメモリの無駄遣いになります。

コードの可読性と書く手間、両方を満足する書き方がパイプ演算子`%>%`です。まずは、例から見ましょう。

```{r, attr.source='.numberLines'}
# %>%を使う
paste(3, "+", 5, "=", 8) %>% rep(3) %>% print()
```

まず、結果は先ほどと同じです。それではコードの説明をしましょう。まずは、`paste(3, "+", 5, "=", 8)`を実行します。そしてその結果をそのまま`rep()`関数の第一引数として渡されます。つまり、`rep(paste(3, "+", 5, "=", 8), 3)`になるわけです。ここでは`rep(3)`と書きましたが、第一引数が渡されたため、`3`は第二引数扱いになります (パイプ演算子前のオブジェクトを第二、三引数として渡す方法は適宜説明します。)。そして、これをまた`print()`関数に渡します。結果としては`print(rep(paste(3, "+", 5, "=", 8), 3))`となります。

関数を重ねると読む順番は「カッコの内側から外側へ」になりますが、パイプ演算子を使うと「左 (上)から右 (下)へ」といったより自然な読み方が可能になります。また、以下のコードのように、パイプ演算子後に改行を行うことでより読みやすいコードになります。これからはパイプ演算子の後は必ず改行をします。

```{r, attr.source='.numberLines', eval = FALSE}
# 改行 (+字下げ)したらもっと読みやすくなる
paste(3, "+", 5, "=", 8) %>% 
    rep(3) %>% 
    print()
```

データハンドリングは様々な作業を順に沿ってに行う必要があります。例えば、「(1) 列を選択して、(2) 欠損値を含む列を除去して、 (3) ある変数の値を100倍にして、(4) ある変数の値がが小さい行から大きい順へ並び替える」といった手順です。これらの作業はパイプ演算子を使えば、スムーズに行うことが可能です。

## 列の抽出

### 特定の列を抽出する

まずは、データフレーム (または、tibble)から特定の列のみを残す、除去する方法について紹介します。たとえば、`df`から`ID`、`Name`、`Pref`、`Score`のみを残すとします。`dplyr`を使わない方法と`dplyr`の`select()`関数を使った方法を紹介します。

```{r, attr.source='.numberLines'}
# dplyrを使わない方法
df[, c("ID", "Name", "Pref", "Score")]

# dplyr::select()を使う方法
# select(df, ID, Name, Pref, Score)でもOK
df %>%
  select(ID, Name, Pref, Score)
```

どれも結果は同じですが、`select()`関数を使った方がより読みやすいコードになっているでしょう。むろん、`select()`関数を使わない方がスッキリする方も知るかも知れません。実際、自分でパッケージなどを作成する際は`select()`を使わない場合が多いです。ただし、一般的な分析の流れでは`select()`の方がコードも意味も明確となり、パイプ演算子でつなぐのも容易です。

`select()`関数の使い方は非常に簡単です。第一引数はデータフレーム (または、tibble)ですが、パイプ演算子を使う場合は省略可能です。第二引数以降の引数はデータフレーム/tibble内の変数名です。つまり、ここには残す変数名のみを書くだけで十分です。

また、`select()`関数を使って列の順番を変えることもできます。たとえば、`ID`、`Pref`、`Name`、`Score`の順で列を残すなら、この順番で引数を書くだけです。

```{r, attr.source='.numberLines'}
df %>%
  select(ID, Pref, Name)
```

### 特定の列を抽出し、列名を変更する

また、特定の列を残す際、変数名を変更することも可能です。今回も`ID`、`Name`、`Pref`、`Score`のみを残しますが、`Pref`列は`Prefecture`に変えてみましょう。

```{r, attr.source='.numberLines'}
df %>%
  select(ID, Name, Prefecture = Pref, Score)
```

抽出する際、変数を`新しい変数名 = 既存の変数名`にするだけで、変数名が簡単に変更できました。もし、特定の列は抽出しないものの、変数名を変えるにはどうすれば良いでしょうか。ここでは`df`の`Pref`を`Prefecture`に、`Walk`を`Distance`に変更してみます。`dplyr`を使わない場合と`dplyr`の`rename()`関数を使う場合を両方紹介します。

まずは、`name()`関数についてですが、これはデータフレーム (または、tibble)の変数名をベクトルとして出力する関数です。

```{r, attr.source='.numberLines'}
names(df)
```

察しの良い読者は気づいたかも知れませんが、`names(データフレーム/tibble名)`の結果はベクトルであり、上書きも可能です。つまり、`names(df)`の3番目と9番目の要素を`"Prefecture"`と`"Distance"`に上書きすることができるということです。

```{r, attr.source='.numberLines'}
# dplyrを使わずに列名を変更する方法
names(df)[c(3, 9)] <- c("Prefecture", "Distance")

# dfの中身を出力
df
```

簡単に変数名の変更ができました。続いて、`dplyr`の`rename()`関数を使った方法です。今回は、`Prefecture`を`Pref`に、`Distance`を`Walk`に戻して見ましょう。そして、出力するだけにとどまらず、`df`に上書きしましょう。

```{r, attr.source='.numberLines'}
# dfのPrefectureをPrefに、DistanceをWalkに変更し、上書きする
df <- df %>%
  rename(Pref = Prefecture, Walk = Distance)
```

これで終わりです。実は`select()`関数と使い方がほぼ同じです。ただし、残す変数名を指定する必要がなく、名前を変更する変数名と新しい変数名を入れるだけです。変数が少ないデータなら`select()`でもあまり不便は感じないかも知れませんが、変数が多くなると`rename()`関数は非常に便利です。

### 特定の列を除外する

逆に、一部の変数をデータフレーム (または、tibble)から除去したい場合もあるでしょう。たとえば、緯度 (`Latitude`)と経度 (`Longitude`)はラーメン屋の情報としては不要かもしれません。この2つの変数を除外するためにはどうすれば良いでしょうか。まず考えられるのは、この2つの変数を除いた変数を指定・抽出する方法です。

```{r, attr.source='.numberLines'}
df %>%
  select(ID, Name, Pref, Zipcode, 
         Line, Station, Walk, Bus, Car, Budget, ScoreN, Score)
```

かなり長いコードになりましたね。しかし、もっと簡単な方法があります。それは`-`を使う方法です。

```{r, attr.source='.numberLines'}
df %>%
  select(-Latitude, -Longitude) # select(-c(Latitude, Longitude))
```

除外したい変数名の前に`-`を付けただけです。また、`-Latitude`と`-Longitude`をそれぞれ指定せず、`-c(Latitude, Longitude)`のように`c()`でまとめるのも可能です。

### 隣接した列を指定する

先ほど、`df`から緯度 (`Latitude`)と経度 (`Longitude`)を除外する例を考えてみましょう。`-`を使うと簡単ですが、場合によっては残す変数名を指定する必要もあります。

```{r, attr.source='.numberLines', eval = FALSE}
df %>%
  select(ID, Name, Pref, Zipcode, 
         Line, Station, Walk, Bus, Car, Budget, ScoreN, Score)
```

よく考えてみれば、`ID`から`Zipcode`は隣接した列ですし、`Line`から`Score`までもそうです。これは`names()`関数で確認できます。

```{r, attr.source='.numberLines'}
names(df)
```

ここで便利な演算子が`:`です。これまで、`x`から`y`までの公差1の等差数列を作成する際に`x:y`を使って来ましたが、これに非常に似ています。データフレーム (または、tibble)の「`x`列から`y`列まで」の表記も`select()`関数内では`:`と書くことができます。したがって、上記のコードは以下のように短縮化可能です。

```{r, attr.source='.numberLines', eval = FALSE}
df %>%
  select(ID:Zipcode, Line:Score)
```

「`df`の`ID`から`Zipcode`まで、そして`Line`から`Score`までの列を選択する」という意味です。非常に便利な演算子ですので、`-`と合わせて覚えておきましょう。

### 一部の列の順番だけを変える

ある列の位置を替えたいとします。たとえば、`Score`と`ScoreN`をそれぞれ1列目、2列目にしたい場合、どうすれば良いでしょうか。これまで勉強したことを考えると、以下のようなコードで問題ないでしょう。

```{r, attr.source='.numberLines'}
df %>%
  select(Score, ScoreN, ID:Budget)
```

しかし、`dplyr`には`relocate()`というより便利な専用関数を提供しています。`relocate()`には変数名を指定するだけですが、ここで指定した変数がデータフレーム (または、tibble)の最初列の方に移動します。

```{r, attr.source='.numberLines'}
df %>%
  relocate(Score, ScoreN)
```

`relocate()`を使うと`ID:Budget`が省略可能となり、より短いコードになります。もう一つの例は、最初に持ってくるのではなく、「ある変数の前」または「ある変数の後」に移動させるケースです。これも`relocate()`で可能ですが、もう一つの引数が必要です。`Pref`と`Zipcdoe`の順番を変えるなら、まずは以下のような方法が考えられます。

```{r, attr.source='.numberLines'}
df %>%
  select(ID:Name, Zipcode, Pref, Latitude:Score)
```

これを`relocate()`で書き換えるなら、`.after`または`.before`引数が必要になります。`relocate(変数名1, .after = 変数名2)`は「変数1を変数2の直後に移動させる」
ことを意味します。

```{r, attr.source='.numberLines'}
df %>%
  relocate(Pref, .after = Zipcode)
```

`.before`を使うことできます。この場合は「`Zipcode`を`Pref`の直前に移動させる」
ことを指定する必要があります。結果は省略しますが、自分でコードを走らせ、上と同じ結果が得られるかを確認してみてください。


```{r, attr.source='.numberLines', eval = FALSE}
df %>%
  relocate(Zipcode, .before = Pref)
```

### `select()`の便利な機能

`select()`関数は他にも便利な機能がいくつかあります。ここではいくつの機能を紹介しますが、より詳しい内容は`?dplyr::select`を参照してください。

**`starts_with()`と`ends_with()`、`contains()`、`num_range()`: 特定の文字を含む変数を選択する**

まずは、特定の文字を含む変数名を指定する方法です。`starts_with("X")`、`ends_with("X")`、`contains("X")`は変数名が`"X"`で始まるか、`"X"`で終わるか、`"X"`を含むかを判断し、条件に合う変数名を返す関数です。実際の例を見ましょう。

```{r, attr.source='.numberLines'}
# ID、Nameに続いて、Scoreで始まる変数名を抽出
df %>%
  select(ID, Name, starts_with("Score"))

# eで終わる変数名を除去
df %>%
  select(-ends_with("e")) # !ends_with("e")も可能

# reを含む変数名を抽出するが、ScoreNは除去する
df %>%
  select(contains("re"), -ScoreN)
```

他の使い方としては`X1`、`X2`のような「文字+数字」の変数を選択する際、`starts_with()`が活躍します。たとえば、以下のような`myDF1`があるとします。

```{r, attr.source='.numberLines'}
# tibble()の代わりにdata.frame()も使用可能
myDF1 <- tibble(
  ID  = 1:5,
  X1  = c(2, 4, 6, 2, 7),
  Y1  = c(3, 5, 1, 1, 0),
  X1D = c(4, 2, 1, 6, 9),
  X2  = c(5, 5, 6, 0, 2),
  Y2  = c(3, 3, 2, 3, 1),
  X2D = c(8, 9, 5, 0, 1),
  X3  = c(3, 0, 3, 0, 2),
  Y3  = c(1, 5, 9, 1, 3),
  X3D = c(9, 1, 3, 3, 8)
)

myDF1
```

この`myDF1`から`ID`、`Y1`、`Y2`、`Y3`を抽出するにはどうすれば良いでしょうか。これらの変数は隣接していないため、`:`も使えませんが、`starts_with()`を使えば簡単です。

```{r, attr.source='.numberLines'}
myDF1 %>%
  select(ID, starts_with("Y"))
```

それでは、`ID`、`X1`、`X2`、`X3`はどうでしょうか。`starts_with("X")`だと、`X1c`なども選択されてしまいますね。ここで`-ends_with()`の出番です。つまり、「まずは`starts_with("X")`で`X`で始まる変数を選択し、続いて、`D`で終わるものを除外すればいいじゃん？」です。それでは、やってみましょうか。

```{r, attr.source='.numberLines'}
myDF1 %>%
  select(ID, starts_with("X"), -ends_with("D"))
```

あらら、`ID`も同時になくなりましたね[^numrange]。実はこのような時のために用意された関数があり、それが`num_range()`です。`num_range()`の第一引数は`starts_with()`関数と同じですが、第二引数も必要です。この第二引数にはnumeric型のベクトルが必要です。`1:3`でも、`c(1, 2, 3)`でも構いません。たとえば、`ID`、`X1`、`X2`、`X3`するには以下のように書きます。

[^numrange]: 実は`select(starts_with("X"), -ends_with("D"), ID)`のように順番を変えると`ID`は最後の列になりますが、とりあえず残ります。なぜなら、`select()`関数は左側から右側の方へコードを実行するからです。

```{r, attr.source='.numberLines'}
myDF1 %>%
  select(ID, num_range("X", 1:3))
```

ぱっぱらぱー！

**`all_of()`と`any_of()`: 文字型ベクトルを用いた変数の選択**

`all_of()`と`any_of()`は`select()`内の変数名として文字型ベクトルを使う際に用いる関数です。これは抽出したい列名が既にcharacter型ベクトルとして用意されている場合、便利な関数です。たとえば、以下の`Name_Vec`を考えてみましょう。

```{r, attr.source='.numberLines'}
Name_Vec <- c("X1", "X2", "X3")
```

この`Name_Vec`の要素と同じ列名を持つ列と`ID`列を`myDF1`から抽出する方法は以下の2通りです。

```{r, attr.source='.numberLines'}
myDF1[, c("ID", Name_Vec)]

myDF1 %>%
  select(ID, all_of(Name_Vec))
```

今の例だと、`select()`を使わない前者の方が便利かも知れませんが、`select()`内に外の変数名も指定する場合も多いので、後者の方が汎用性は高いです。私から見れば、今の例でも後者の方が読みやすく、使いやすいと思います。

それでは以下のような`Name_Vec`はどうでしょう。今回は、`myDF1`に含まれていない`X4`と`X5`もあります。

```{r, attr.source='.numberLines', error = TRUE}
Name_Vec <- c("X1", "X2", "X3", "X4", "X5")

myDF1 %>%
  select(all_of(Name_Vec))
```

このようにエラーが出てしまします。つまり、`all_of()`の場合、引数の要素全てがデータフレーム (または、tibble)に存在する必要があります。もし、ないものは無視して、合致する列だけ取り出したいはどうすれば良いでしょうか。そこで登場するのが`any_of()`です。

```{r, attr.source='.numberLines'}
myDF1 %>%
  select(any_of(Name_Vec))
```

`any_of()`の方がより使いやすいと思う方も多いでしょうが、必ずしもそうとは限りません。たとえば、`Name_Vec`に誤字などが含まれる場合、`any_of()`だと誤字が含まれている変数は取り出しません。この場合はむしろちゃんとエラーを表示してくれた方が嬉しいですね。

**`last_col()`: 最後の列を選択する**

普段あまり使わない機能ですが、最後の列を選択する`last_col()`という関数もあります。たとえば、`last_col(0)`にすると最後の列を選択し、`last_col(1)`なら最後から2番目の列を選択します。たとえば、`df`から`ID`と最後の列を取り出してみましょう。

```{r, attr.source='.numberLines'}
# IDと最後の列のみを抽出
df %>%
  select(ID, last_col(0))
```

最後の2行分を取り出すことも可能です。この場合は`last_col()`の引数を長さ1ベクトルでなく、長さ2以上のベクトルにします。最後の行が`0`、その手前の行が`1`ですから、中の引数は`1:0`となります。`0:1`でも可能ですが、結果が若干異なります。

```{r, attr.source='.numberLines'}
# IDと最後の2列分を抽出 (引数を1:0と設定)
df %>%
  select(ID, last_col(1:0))
```

```{r, attr.source='.numberLines'}
# IDと最後の2列分を抽出 (引数を0:1と設定)
df %>%
  select(ID, last_col(0:1))
```

`last_col()`の引数を`1:0`にするか`0:1`にするかによって抽出される順番が異なります。`1:0`は`c(1, 0)`、`0:1`は`c(0, 1)`と同じであることを考えると理由は簡単です。`c(1, 0)`の場合、`last_col(1), last_col(0)`の順番で処理をし、`c(0, 1)`は`last_col(0)`、`last_col(1)`の順番で処理を行うからです。

この`last_col()`の引数を空っぽにするとそれは最後の列を意味します。これを利用すれば、「ある変数の最後の列へ移動させる」こともできます。たとえば、`ID`を最後の列に移動させたい場合、`relocate(ID, .after = last_col())`のように書きます。

**`where()`: データ型から変数を選択する**

最後に、「numeric型の列のみ抽出したい」、「character型の列だけほしい」場合に便利な`where()`関数を紹介します。`where()`の中に入る引数は一つだけであり、データ型を判定する関数名が入ります。たとえば、numeric型か否かを判断する関数は`is.numeric`です。`df`からnumeric型の変数のみを抽出したい場合は以下のように書きます。

```{r, attr.source='.numberLines'}
# numeric型の列を抽出する
df %>%
  select(where(is.numeric))
```

`!`を使って条件に合致する列を除外することも可能です。もし、character型の列を除外する場合は以下のように`!where(is.character)`を指定します。

```{r, attr.source='.numberLines'}
# character型でない列を抽出する
df %>%
  select(!where(is.character))
```

`&`を使って複数の条件を使うことも可能です。たとえば、`ID`変数に加えて「`"L"`で始まる変数の中でnumeric型の列を抽出」するコードは以下のようになります。

```{r, attr.source='.numberLines'}
# IDと、Lで始まるnumeric型の列を抽出する
df %>%
  select(ID, starts_with("L") & where(is.numeric))
```

---

## 行の抽出

他にも特定の行を抽出する場合があります。多くの場合、「何かの条件と合致するケースのみ抽出する」または、「何かの条件と合致しないケースのみを抽出する」やこれらの組み合わせで行の抽出を行います。そこで登場するのが`dplyr()`パッケージの`filter()`関数です。`filter()`関数の使い方は以下の通りです。

```{r, attr.source='.numberLines', eval = FALSE}
# dplyr::filter()の使い方
filter(データフレーム/tibble名, 条件1, 条件2, ...)
```

むろん、第一引数がデータですから、`%>%`を使うことも可能です。

```{r, attr.source='.numberLines', eval = FALSE}
# dplyr::filter()の使い方 (パイプを使う方法)
データフレーム/tibble名 %>%
  filter(条件1, 条件2, ...)
```

まずは、条件が一つの場合を考えてみましょう。ここでは「`Pref`が`"京都府"`であるケースのみに絞り、`Name`と`Station`、`Score`列のみを出力する」ケースを考えてみましょう。まず、`filter()`関数で行を抽出し、続いて`select()`関数で抽出する列を指定します。むろん、今回の場合、`filter()`と`select()`の順番は替えても構いません。

```{r, attr.source='.numberLines'}
# dfからPrefが"京都府"であるケースのみ残し、df2という名で保存
df2 <- df %>%
  filter(Pref == "京都府")

# df2からName, Station, Score列を抽出
df2 %>%
  select(Name, Station, Score)
```

これは`df`から`Pref == "京都府"`のケースのみ残したものを`df2`として格納し、それをまた`select()`関数を使って列を抽出するコードです。これでも問題ありませんが、これだとパイプ演算子の便利さが分かりません。パイプ演算子は複数使うことが可能です。

```{r, attr.source='.numberLines'}
df %>%
  filter(Pref == "京都府") %>%
  select(Name, Station, Score)
```

全く同じ結果ですが、無駄に`df2`というデータフレーム (または、tibble)を作らず済むので、メモリの観点からも嬉しいですし、何よりコードが短く、しかも可読性も上がりました。

今回は`==`を使って**合致する**ものに絞りましたが、`!=`を使って**合致しない**ものに絞ることも可能です。または、比較演算子 (`<`、`>`、`>=`、`<=`など)を使うことも可能です。それでは、組み込み数 (`ScoreN`)が*0ではない*ケースを取り出し、`Name`、`Station`、`ScoreN`、`Score`列を出力させてみましょう。

```{r, attr.source='.numberLines'}
df %>%
  filter(ScoreN != 0) %>%
  select(Name, Station, starts_with("Score"))
```

これで口コミ数が1以上の店舗のみに絞ることができました。ただし、店によっては口コミはあっても、評価 (`Score`)が付いていないところもあります。たとえば、「刀削麺・火鍋・西安料理 XI'AN（シーアン） 後楽園店」の場合、口コミはありますが、評価はありません。したがって、今回は評価が付いている店舗に絞ってみましょう。

```{r, attr.source='.numberLines'}
df %>%
  filter(Score != NA) %>%
  select(Name, Station, starts_with("Score"))
```

あらら、何の結果も表示されませんでした。これは`filter()`内の条件に合致するケースが存在しないことを意味します。しかし、先ほどの結果を見ても、評価が付いている店はいっぱいありましたね。これはなぜでしょう。

察しの良い読者さんは気づいているかと思いますが、`NA`か否かを判定する際は`==`や`!=`は使えません。`is.na()`を使います。`filter(is.na(Score))`なら「`Score`が`NA`**である**ケースに絞る」ことを意味しますが、今回は「`Score`が`NA`**でない**ケースに絞る」ことが目的ですので、`is.na()`の前に`!`を付けます。

```{r, attr.source='.numberLines'}
df %>%
  filter(!is.na(Score)) %>%
  select(Name, Station, starts_with("Score"))
```

これで口コミ評価が登録された店舗に絞ることができました。

続いて、複数の条件を持つケースを考えてみましょう。例えば、「京都府内の店舗で、口コミ評価が3.5以上の店舗」を出力したい場合、以下のようなコードとなります。

```{r, attr.source='.numberLines'}
df %>%
  filter(Pref == "京都府", Score >= 3.5) %>%
  select(Name, Station, ScoreN, Score)
```

条件を`filter()`内に追加するだけです。今回は`!is.na(Score)`は不要です。なぜなら、`Score >= 3.5`という条件で既に欠損値は対象外になるからです。条件文が複数ある場合、ANDかORかを指定する必要があります。つまり、条件文AとBがある場合、「AとB両方満たすものを出力する」か「AとBどちらかを満たすものを出力するか」を指定する必要があります。今の結果ってANDでしたよね。`filter()`関数は、別途の指定がない場合、全てAND扱いになります。RのAND演算子は`&`ですので、以上のコードは以下のコードと同じです。

```{r, attr.source='.numberLines'}
df %>%
  filter(Pref == "京都府" & Score >= 3.5) %>%
  select(Name, Station, ScoreN, Score)
```

AND演算子 (`&`)が使えるということはOR演算子 (`|`)も使えることを意味します。たとえば、`Station`が`"高田馬場駅"`か`"三田駅"`の条件を指定したい場合、

```{r, attr.source='.numberLines'}
df %>% 
  filter(Station == "高田馬場駅" | Station == "三田駅") %>%
  select(Name, Station, ScoreN, Score)
```

のように書きます（ちなみに高田馬場の「やまぐち」は本当に美味しいです）。むろん、複数の変数を用いたORも可能です。たとえば、「`Pref`が`"京都府"`か`Score`が3以上」のような条件も可能ですが (`Pref == "京都府" | Score >= 3`)、実際、このような例はあまりありません。よく使うのは「変数`X`が`a`か`b`か`c`か」のような例です。ただし、この場合は`|`を使わないもっと簡単な方法があります。それは`%in%`演算子です。以下のコードは上のコードと同じものです。

```{r, attr.source='.numberLines'}
df %>% 
  filter(Station %in% c("高田馬場駅", "三田駅")) %>%
  select(Name, Station, ScoreN, Score)
```

結局、`|`が使われるケースがかなり限定されます。あるとすれば、「変数`X`が`a`以下か、`b`以上か」のようなケースですね。ただし、`&`と`|`を同時に使うケースは考えられます。たとえば、大阪駅と京都駅周辺のうまいラーメン屋を調べるとします。問題は美味しさの基準ですが、3.5点以上としましょう。ただし、京都府民はラーメンに非常に厳しく、3点以上なら美味しいと仮定します。この場合、「(`Station`が`"大阪駅"`かつ`Score >= 3.5`)、または(`Station`が`"京都駅"`かつ`Score >= 3`)」のような条件が必要になります。`()`は「`()`の中から判定せよ」という、普通の算数での使い方と同じです。それでは、実際に検索してみましょう。

```{r, attr.source='.numberLines'}
df %>%
  filter((Station == "大阪駅" & Score >= 3.5) | (Station == "京都駅" & Score >= 3)) %>%
  select(Name, Station, Walk, ScoreN, Score)
```

Songが大好きな神座がヒットして嬉しいです。

---

## 行のソート

続いて、行のソートについて解説します。「食べログ」などのレビューサービスを利用する場合、口コミ評価が高い順で見るのが一般的でしょう[^tabelog]。また、サッカーのランキングも多くは1位から下の順位で掲載されるのが一般的です。ここではこのようにある変数の値順に行を並び替える方法について説明します。

[^tabelog]: サービスによってはこの機能が有料になっていたりもしますね。

ソートには`dplyr`パッケージの`arrange()`関数を使います。引数は変数名のみです。たとえば、奈良県のラーメン屋を検索してみましょう。並び替える順は駅から近い店舗を上位に、遠い店舗を下位に並べます。このような順は**昇順 (ascending)**と呼ばれ、ランキング表などでよく見ます。駅から近い順にソートするので、まず最寄りの駅情報が欠損でないことが必要です。また、ラーメン屋の評価も気になるので口コミが1つ以上付いている店舗に絞りましょう。表示する列は店舗名、最寄りの駅、徒歩距離、口コミ数、点数です。

```{r, attr.source='.numberLines'}
df %>%
  filter(Pref == "奈良県", !is.na(Station), ScoreN > 0) %>%
  select(Name, Station, Walk, ScoreN, Score) %>%
  arrange(Walk) %>%
  print(n = Inf)
```

3行まではこれまで習ってきたもので、4行目がソートの関数、`arrange()`です。引数はソートの基準となる変数で、今回は最寄りの駅からの徒歩距離を表す`Walk`です。5行目は省略可能ですが、`tibble`クラスの場合、10行までしか出力されないので、`print(n = Inf)`で「すべての行を表示」させます。`n`を指定することで出力される行数が調整可能です。奈良県のラーメン屋の中で最寄りの駅から最も近い店は「[麺屋 あまのじゃく 本店](https://www.menya-amanojaku.com)」で徒歩2分でした。京田辺店も駅から約2分ですし、近いですね。ちなみにSongはここの塩とんこつが好きです。世界一こってりなラーメンとも言われる「チョモランマ」で有名な「[まりお流ラーメン](http://www.marioramen.com)」は新大宮駅から徒歩20分でかなり遠いことが分かります。

続いて、駅からの距離ではなく、評価が高い順にしてみましょう。評価が高いほど上に来るので、今回は昇順でなく、**降順 (descending)**でソートする必要があります。`arrange()`関数は基本的に、指定された変数を基準に昇順でソートします。降順にするためには`desc()`関数を更に用います。たとえば、`arrange(desc(変数名))`のようにです。それでは実際にやってみましょう。上のコードの4行目を`arange(Walk)`から`arrange(desc(Score))`にちょっと修正するだけです。

```{r, attr.source='.numberLines'}
df %>%
  filter(Pref == "奈良県", !is.na(Station), ScoreN > 0) %>%
  select(Name, Station, Walk, ScoreN, Score) %>%
  arrange(desc(Score)) %>%
  print(n = Inf)
```

よく考えてみれば、「評価が同点の場合、どうなるの?」と疑問を抱く方がいるかも知れません。たとえば、7行目の「河童ラーメン本舗 押熊店」と8行目の「無鉄砲がむしゃら」はどれも評価が4点ですが、「河童ラーメン本舗 押熊店」が先に表示されます。そのこれは簡単です。同点の場合、データセット内で上に位置する行が先に表示されます。これを確認するには`which()`関数を使います。`()`内に条件文を指定することで、この条件に合致する要素の位置を返します。もし、条件に合致するものが複数あった場合は全ての位置を返します[^which]。

[^which]: たとえば、データ内に「ラーメンショップ」という店舗は3店舗あり、この場合、長さ3のベクトルが返されます。

```{r, attr.source='.numberLines'}
which(df$Name == "河童ラーメン本舗 押熊店")
which(df$Name == "無鉄砲がむしゃら")
```

データ内に「河童ラーメン本舗 押熊店」がより上に位置することが分かります。「もし同点なら口コミ評価数が多いところにしたい」場合はどうすれば良いでしょうか。これは`arrange()`内に変数名を足すだけで十分です。

```{r, attr.source='.numberLines'}
df %>%
  filter(Pref == "奈良県", !is.na(Station), ScoreN > 0) %>%
  select(Name, Station, Walk, ScoreN, Score) %>%
  arrange(desc(Score), desc(ScoreN)) %>%
  print(n = Inf)
```

ソートの基準は`arrange()`内において先に指定された変数の順番となります。「口コミ評価も評価数も同じなら、駅から近いところにしたい」場合は変数が3つとなり、`Score`、`ScoreN`、`Walk`の順で入れます。

```{r, attr.source='.numberLines'}
df %>%
  filter(Pref == "奈良県", !is.na(Station), ScoreN > 0) %>%
  select(Name, Station, Walk, ScoreN, Score) %>%
  arrange(desc(Score), desc(ScoreN), Walk) %>%
  print(n = Inf)
```

---

## 記述統計量の計算

### `summarise()`による記述統計量の計算

ある変数の平均値や標準偏差、最小値、最大値などの記述統計量 (要約統計量)を計算することも可能です。これは`summarize()`または`summarise()`関数を使いますが、この関数は後で紹介する`group_by()`関数と組み合わせることで力を発揮します。ここではグルーピングを考えずに、全データの記述統計量を計算する方法を紹介します。

`summarise()`関数の使い方は以下の通りです。

```{r, attr.source='.numberLines', eval = FALSE}
# summarise()関数の使い方
データフレーム/tibble名 %>%
  summarise(新しい変数名 = 関数名(計算の対象となる変数名))
```

もし、`Score`変数の平均値を計算し、その結果を`Mean`という列にしたい場合は以下のようなコードになります。

```{r, attr.source='.numberLines'}
df %>%
  summarise(Mean = mean(Score))
```

ただし、`mean()`関数は欠損値が含まれるベクトルの場合、`NA`を返します。この場合方法は2つ考えられます。

1. `filter()`関数を使って`Score`が欠損しているケースを予め除去する。
2. `na.rm`引数を指定し、欠損値を除去した平均値を求める。

ここでは2番目の方法を使います。

```{r, attr.source='.numberLines'}
df %>%
  summarise(Mean = mean(Score, na.rm = TRUE))
```

`df`の`Score`変数の平均値は`r round(mean(df$Score), 2)`であることが分かります。また、`summarise()`関数は複数の記述統計量を同時に計算することも可能です。以下は`Score`変数の平均値、中央値、標準偏差、最小値、最大値、第一四分位点、第三四分位点を計算し、`Score.Desc`という名のデータフレーム (または、tibble)に格納するコードです。

```{r, attr.source='.numberLines'}
Score.Desc <- df %>%
  summarize(Mean   =     mean(Score,       na.rm = TRUE),  # 平均値
            Median =   median(Score,       na.rm = TRUE),  # 中央値
            SD     =       sd(Score,       na.rm = TRUE),  # 標準偏差
            Min    =      min(Score,       na.rm = TRUE),  # 最小値
            Max    =      max(Score,       na.rm = TRUE),  # 最大値
            Q1     = quantile(Score, 0.25, na.rm = TRUE),  # 第一四分位点
            Q3     = quantile(Score, 0.75, na.rm = TRUE))  # 第三四分位点
```

```{r, attr.source='.numberLines'}
Score.Desc
```

むろん、複数の変数に対して記述統計量を計算することも可能です。たとえば、平均予算 (`Budget`)、口コミ数 (`ScoreN`)、口コミ評価 (`Score`)の平均値を求めるとしたら、

```{r, attr.source='.numberLines'}
df %>%
  summarize(Budget_Mean = mean(Budget, na.rm = TRUE), # 平均予算の平均値
            SocreN_Mean = mean(ScoreN, na.rm = TRUE), # 口コミ数の平均値
            Score_Mean  = mean(Score,  na.rm = TRUE)) # 評価の平均値
```

のように書きます。実は`summarise()`はこれくらいで十分便利です。ただし、以上の操作はもっと簡単なコードに置換できます。ただし、ラムダ式など、やや高度な内容になるため、以下の内容は飛ばして、次の節 (グルーピング)を読んでいただいても構いません。

まずは、複数の変数に対して同じ記述統計量を求める例を考えてみましょう。たとえば、`Budget`、`ScoreN`、`Score`に対して平均値を求める例です。これは`across()`関数を使うとよりコードが短くなります。まずは`across()`関数の書き方から見ましょう。

```{r, attr.source='.numberLines', eval = FALSE}
# across()の使い方
データフレーム/tibble名 %>%
  summarise(across(変数名のベクトル, 記述統計を計算する関数名, 関数の引数))
```

*変数名のベクトル*は長さ1以上のベクトルです。たとえば、`Budget`、`ScoreN`、`Score`の場合`c(Budget, ScoreN, Score)`になります。これは`df`内で隣接する変数ですから`Budget:Score`の書き方も使えます。また、`where()`や`any_of()`、`starts_with()`のような関数を使って変数を指定することも可能です。*関数名*は`mean`や`sd`などの関数名です。ここは`関数名()`でななく、`関数名`であることに注意してください。*引数*は前の関数に必要な引数です。引数を必要としない関数なら省略可能ですが、`na.rm = TRUE`などの引数が必要な場合は指定する必要があります。それでは`Budget`、`ScoreN`、`Score`の平均値を計算してみましょう。

```{r, attr.source='.numberLines'}
df %>%
  summarize(across(Budget:Score, mean, na.rm = TRUE))
```

`across()`使わない場合、4行必要だったコードが2行になりました。変数が少ない場合は`across()`を使わない方が、可読性が高くなる場合もあります。しかし、変数が多くなる場合、可読性がやや落ちても`across()`を使った方が効率的でしょう。

次は、ある変数に対して複数の記述統計量を計算したい場合について考えます。`Budget`、`ScoreN`、`Score`変数の第一四分位点と第三四分位点を`across()`を使わずに計算すると家のような7行のコードになります。

```{r, attr.source='.numberLines'}
df %>%
  summarize(Budget_Q1 = quantile(Budget, 0.25, na.rm = TRUE),
            Budget_Q3 = quantile(Budget, 0.75, na.rm = TRUE),
            ScoreN_Q1 = quantile(ScoreN, 0.25, na.rm = TRUE),
            ScoreN_Q3 = quantile(ScoreN, 0.75, na.rm = TRUE),
            Score_Q1  = quantile(Score,  0.25, na.rm = TRUE),
            Score_Q3  = quantile(Score,  0.75, na.rm = TRUE))
```

この作業も`across()`を使ってより短縮することができます。ここではラムダ式の知識が必要になります。ラムダ関数とは関数名を持たない[無名関数 (anonymous functions)](https://ja.wikipedia.org/wiki/無名関数)を意味しますが、詳細は割愛します。興味のある読者は[Wikipedia](https://ja.wikipedia.org/wiki/無名関数)などを参照してください。簡単にいうとその場で即席に関数を作成し、計算が終わったら破棄する関数です。ただ、Rは基本的にラムダ式を提供しているのではなく、`purrr`パッケージのラムダ式スタイルを使用します。まずは、書き方から確認します。

```{r, attr.source='.numberLines', eval = FALSE}
# ラムダ式を用いたacross()の使い方
データフレーム/tibble名 %>%
  summarise(across(変数名のベクトル, list(結果の変数名 = ラムダ式)))
```

先ほどの書き方と似ていますが、関数を複数書く必要があるため、今回は関数名をlist型にまとめます。そして、*結果の変数名*は結果として出力されるデータフレーム (または、tibble)の列名を指定する引数です。たとえば、`Mean`にすると結果は`元の変数名1_Mean`、`元の変数名2_Mean`...のように出力されます。そして、ラムダ式が実際の関数が入る箇所です。とりあえず今回はコードを走らせ、結果から確認してみましょう。

```{r, attr.source='.numberLines'}
df %>%
  summarize(across(Budget:Score, list(Q1 = ~quantile(.x, 0.25, na.rm = TRUE),
                                      Q3 = ~quantile(.x, 0.75, na.rm = TRUE))))
```

結果の列名が`Budget_Q1`、`Budget_Q3`、`ScoreN_Q1`...のようになり、それぞれの変数の第一四分位点と第三四分位点が出力されます。問題はラムダ式の方ですが、普通の関数に非常に近いことが分かります。`across()`内のラムダ式は`~関数名(.x, その他の引数)`のような書き方になります。関数名の前に`~`が付いていることに注意してください。分位数を求める関数は`quantile()`であり、`quantile(ベクトル, 分位数)`であり、必要に応じて`na.rm`を付けます。この分位数が0.25なら第一四分位点、0.5なら第二四分位点 (=中央値)、0.75なら第三四分位点になります。それではラムダ式`~quantile(.x, 0.25, na.rm = TRUE)`はどういう意味でしょうか。これは`.x`の箇所に`Budget`や`ScoreN`、`Score`が入ることを意味します。`.x`という書き方は決まりです。`.y`とか`.Song-san-Daisuki`などはダメです。そして、`0.25`を付けることによって第一四分位点を出力するように指定します。また、`Budget`、`ScoreN`、`Score`に欠損値がある場合、無視するように`na.rm = TRUE`を付けます。

ラムダ式を自分で定義する関数で表現すると、以下のようになります。

```{r, attr.source='.numberLines', eval = FALSE}
# 以下の3つは同じ機能をする関数である

# ラムダ式
~quantile(.x, 0.25, na.rm = TRUE)

# 一般的な関数の書き方1
名無し関数 <- function(x) {
  quantile(x, 0.25, na.rm = TRUE)
}

# 一般的な関数の書き方2
名無し関数 <- function(x) quantile(x, 0.25, na.rm = TRUE)
```

この3つは全て同じですが、ラムダ式は関数名を持たず、その場で使い捨てる関数です。むろん、ラムダ式を使わずに事前に第一四分位点と第三四分位点を求める関数を予め作成し、ラムダ式の代わりに使うことも可能です。まずは第一四分位点と第三四分位点を求める自作関数`FuncQ1`と`FuncQ2`を作成します。

```{r, attr.source='.numberLines'}
# ラムダ式を使わない場合は事前に関数を定義しておく必要がある
FuncQ1 <- function(x) {
  quantile(x, 0.25, na.rm = TRUE)
}
FuncQ3 <- function(x) {
  quantile(x, 0.75, na.rm = TRUE)
}
```

後は先ほどのほぼ同じ書き方ですが、今回はラムダ式を使わないため関数名に`~`を付けず、関数名のみで十分です。

```{r, attr.source='.numberLines'}
# やっておくと、summarise()文は簡潔になる
df %>%
  summarize(across(Budget:Score, list(Q1 = FuncQ1, Q3 = FuncQ3)))
```

事前に関数を用意するのが面倒ですが、`across()`の中身はかなりスッキリしますね。もし、このような作業を何回も行うなら、ラムダ式を使わず、自作関数を用いることも可能です。ただし、自作関数であっても引数が2つ以上必要な場合はラムダ式を使います。

### `summarise()`に使える便利な関数

以下の内容は後で説明する`group_by()`関数を使っているため、まだ`group_by()`に馴染みのない読者はまずはここを読み飛ばし、グルーピングの節にお進みください。

**`IQR()`: 四分位範囲を求める**

四分位範囲は第三四分位点から第一四分位点を引いた値であり、Rの内蔵関数である`IQR()`を使えば便利です。この関数は`mean`や`sd()`関数と同じ使い方となります。

```{r, attr.source='.numberLines'}
df %>%
  filter(!is.na(Walk)) %>% # 予め欠損したケースを除くと、後でna.rm = TRUEが不要
  group_by(Pref) %>%
  summarise(Mean    = mean(Walk),
            SD      = sd(Walk),
            IQR     = IQR(Walk),
            N       = n(),
            .groups = "drop") %>%
  arrange(Mean)
```

**`first()`、`last()`、`nth()`: n番目の要素を求める**

稀なケースかも知れませんが、データ内、またはグループ内の`n`番目の行を抽出する時があります。たとえば、市区町村の情報が格納されているデータセットで、人口が大きい順でデータがソートされているとします。各都道府県ごとに最も人口が大きい市区町村のデータ、あるいは最も少ない市区町村のデータが必要な際、`first()`と`last()`関数が有効です。

それでは各都道府県ごとに「最も駅から遠いラーメン屋」の店舗名と最寄りの駅からの徒歩距離を出力したいとします。まずは、徒歩距離のデータが欠損しているケースを除去し、データを徒歩距離順でソートします。これは`filter()`と`arrange()`関数を使えば簡単です。続いて、`group_by()`を使って都府県単位でデータをグループ化します。最後に`summarise()`関数内に`last()`関数を使います。データは駅から近い順に鳴っているため、各都府県内の最後の行は駅から最も遠い店舗になるからです。

```{r, attr.source='.numberLines'}
df %>%
  filter(!is.na(Walk)) %>%
  arrange(Walk) %>%
  group_by(Pref) %>%
  summarise(Farthest  = last(Name),
            Distance  = last(Walk),
            .groups   = "drop")
```

この`last()`を`first()`に変えると、最寄りの駅から最も近い店舗情報が表示されます。また、「`n`番目の情報」が必要な際は`nth()`関数を使います。`nth(Name, 2)`に変えることで2番目の店舗名が抽出できます。

**`n_distinct()`: ユニーク値の個数を求める**

`n_distinct()`は何種類の要素が含まれているかを計算する関数であり、`length(unique())`関数と同じ機能をします。たとえば、以下の`myVec1`に対して何種類の要素があるかを確認してみましょう。

```{r, attr.source='.numberLines'}
myVec1 <- c("A", "B", "B", "D", "A", "B", "D", "C", "A")

unique(myVec1)
```

`myVec1`は`"A"`、`"B"`、`"D"`、`"C"`の要素で構成されていることが分かります。これが`myVec1`の**ユニーク値 (unique values)**です。そして、このユニーク値の個数を調べるために`length()`を使います。

```{r, attr.source='.numberLines'}
length(unique(myVec1))
```

これで`myVec1`は4種類の値が存在することが分かります。これと全く同じ機能をする関数が`n_distinct()`です。

```{r, attr.source='.numberLines'}
n_distinct(myVec1)
```

この関数を`summarise()`に使うことで、都府県ごとに駅の個数が分かります。あるいは「東京都内の選挙区に、これまでの衆院選において何人の候補者が存在したか」も分かります。ここでは`df`内の都府県ごとに駅の個数を計算してみましょう。最後の駅数が多い順でソートします。

```{r, attr.source='.numberLines'}
df %>%
  filter(!is.na(Station)) %>% # 最寄りの駅が欠損しているケースを除去
  group_by(Pref) %>%
  summarise(N_Station = n_distinct(Station),
            .groups   = "drop") %>%
  arrange(desc(N_Station))
```

当たり前かも知れませんが、駅数が最も多いのは東京都で次が大阪府であることが分かります。

**`any()`、`all()`: 条件に合致するか否かを求める**

`any()`と`all()`はベクトル内の全要素に対して条件に合致するか否かを判定する関数です。ただし、`any()`は一つの要素でも条件に合致すれば`TRUE`を、全要素が合致しない場合`FALSE`を返します。一方、`all()`は全要素に対して条件を満たせば`TRUE`、一つでも満たさない要素があれば`FALSE`を返します。以下は`any()`と`all()`の例です。

```{r, attr.source='.numberLines'}
myVec1 <- c(1, 2, 3, 4, 5)
myVec2 <- c(1, 3, 5, 7, 11)

any(myVec1 %% 2 == 0) # myVec1を2で割った場合、一つでも余りが0か
all(myVec1 %% 2 == 0) # myVec1を2で割った場合、全ての余りが0か
all(myVec2 %% 2 != 0) # myVec2を2で割った場合、全ての余りが0ではないか
```

それでは実際に`df`に対して`any()`と`all()`関数を使ってみましょう。一つ目は「ある都府県に最寄りの駅から徒歩60分以上の店舗が**一つでも**あるか」であり、二つ目は「ある都府県の店舗は**全て**最寄りの駅から徒歩30分以下か」です。それぞれの結果を`Over60`と`Within30`という列で出力してみましょう。

```{r, attr.source='.numberLines'}
df %>%
  group_by(Pref) %>%
  summarise(Over60   = any(Walk >= 60, na.rm = TRUE),
            Within30 = all(Walk <= 30, na.rm = TRUE),
            .groups  = "drop")
```

埼玉県と神奈川県において、最寄りの駅から徒歩60以上の店がありました。また、京都府、東京都、奈良県、和歌山県の場合、全店舗が最寄りの駅から徒歩30分以下ということが分かります。当たり前ですが`Over60`が`TRUE`なら`Within30`は必ず`FALSE`になりますね。

---

## グルーピング

### `group_by()`によるグループ化

先ほどの`summarise()`関数は確かに便利ですが、特段に便利とも言いにくいです。`df`の`Score`の平均値を計算するだけなら、`summarise()`関数を使わない方が楽です。

```{r, attr.source='.numberLines'}
# これまでのやり方
df %>%
  summarise(Mean = mean(Score, na.rm = TRUE))

# 普通にこれでええんちゃう?
mean(df$Score, na.rm = TRUE)
```

しかし、これをグループごとに計算するならどうでしょう。たとえば、`Score`の平均値を都府県ごとに計算するとします。この場合、以下のようなコードになります。

```{r, attr.source='.numberLines'}
mean(df$Score[df$Pref == "東京都"],   na.rm = TRUE)
mean(df$Score[df$Pref == "神奈川県"], na.rm = TRUE)
mean(df$Score[df$Pref == "千葉県"],   na.rm = TRUE)
mean(df$Score[df$Pref == "埼玉県"],   na.rm = TRUE)
mean(df$Score[df$Pref == "大阪府"],   na.rm = TRUE)
mean(df$Score[df$Pref == "京都府"],   na.rm = TRUE)
mean(df$Score[df$Pref == "兵庫県"],   na.rm = TRUE)
mean(df$Score[df$Pref == "奈良県"],   na.rm = TRUE)
mean(df$Score[df$Pref == "和歌山県"], na.rm = TRUE)
```

変わったのは`df$Score`が`df$Score[df$Pref == "東京都"]`に変わっただけです。`df$Pref`が`"東京都"`であるか否かを`TRUE`と`FALSE`で判定し、これを基準に`df$Score`を抽出する仕組みです。`df$Score`と`df$Pref`は同じデータフレーム (または、tibble)ですから、このような書き方で問題ありません。

これだけでもかなり書くのが面倒ですが、これが47都道府県なら、あるいは200ヶ国ならかなり骨の折れる作業でしょう。ここで大活躍するのが`dplyr`パッケージの`group_by()`関数です。引数はグループ化する変数名だけです。先ほどの作業を`dplyr`を使うなら`Pref`変数でグループ化し、`summarise()`関数で平均値を求めるだけです。今回は`Score`だけでなく、`ScoreN`の平均値も求めてみましょう。そして、評価が高い順にソートもしてみます。

```{r, attr.source='.numberLines'}
# ScoreNとScoreの平均値をPrefごとに求める
df %>%
  group_by(Pref) %>%
  summarise(ScoreN_Mean = mean(ScoreN, na.rm = TRUE),
            Score_Mean  = mean(Score,  na.rm = TRUE)) %>%
  arrange(desc(Score_Mean))
```

評判が最も高い都府県は和歌山県、最も低いのは神奈川県ですね。Songも和歌山ラーメンは井出系も車庫前系も好きです。しかし、大事なのは「井出系」と「車庫前系」といった分類が正しいかどうかではありません。コードが非常に簡潔となり、ソートなども自由自在であることです。都府県ごとに`ScoreN`と`Score`の平均値を求める場合、`dplyr()`を使わなかったら18行のコードとなり、ソートも自分でやる必要があります。一方、`group_by()`関数を使うことによってコードが5行になりました。

また、これは2020年6月に公開された`dplyr`1.0.0からの問題ですが、`group_by()`の後に`summarise()`を使うと以下のようなメッセージが出力されます。

```
## `summarise()` ungrouping output (override with `.groups` argument)
```

これは`group_by()`で指定された変数のグループ化が自動的に解除されたことを意味します。なぜなら`summarise()`をする際は`Pref`をグループ変数として使いましたが、出力された結果の`Pref`変数はもはやグループとして機能できなくなるからです。元の`df`には`Pref`が`"東京都"`だったケースが1000行、`"京都府"`だったのが414行あったので、`Pref`変数でグループ化する意味がありました。しかし、`summarise()`から得られたデータフレーム (または、tibble)は`Pref == "東京都"`の行が1つしかありません。これはグループ化する意味がなくなったことを意味します。したがって、自動的にグループを解除してくれます。自動的にやってくれるのはありがたいことですが、可能ならば関数内に自分で明記することが推奨されます。そこで使う引数が`.groups`であり、`"drop"`を指定すると**全ての**グループ化変数を解除します。以下のようなコードだと先ほどのメッセージが表示されません。今後、意識的に入れるようにしましょう。

```{r, attr.source='.numberLines'}
# ScoreNとScoreの平均値をPrefごとに求める
df %>%
  group_by(Pref) %>%
  summarise(ScoreN_Mean = mean(ScoreN, na.rm = TRUE),
            Score_Mean  = mean(Score,  na.rm = TRUE),
            .groups     = "drop") %>%
  arrange(desc(Score_Mean))
```

続いて、一つ便利な関数を紹介します。それはグループのサイズを計算する関数、`n()`です。この関数を`summarise()`内に使うと、各グループに属するケース数を出力します。先ほどのコードを修正し、各グループのサイズを`N`という名の列として追加してみましょう。そしてソートの順番は`N`を最優先とし、同じ場合は`Score_Mean`が高い方を上に出力させます。また、`ScoreN_Mean`の前に、口コミ数の合計も出してみましょう。

```{r, attr.source='.numberLines'}
# Prefごとに口コミ数の合計、口コミ数の平均値、評価の平均値、店舗数を求める
# 店舗数-評価の平均値順でソートする
df %>%
  group_by(Pref) %>%
  summarise(ScoreN_Sum  = sum(ScoreN,  na.rm = TRUE),
            ScoreN_Mean = mean(ScoreN, na.rm = TRUE),
            Score_Mean  = mean(Score,  na.rm = TRUE),
            N           = n(),
            .groups     = "drop") %>%
  arrange(desc(N), desc(Score_Mean))
```

記述統計をグループごとに求めるのは普通にあり得るケースですし、実験データの場合はほぼ必須の作業でう。統制群と処置群間においてグループサイズが均一か、共変量のバラツキが十分に小さいかなどを判断する際に`group_by()`と`summarise()`関数の組み合わせは非常に便利です。

### 複数の変数を用いたグループ化

グループ化変数は2つ以上指定することも可能です。たとえば、都府県 (`Pref`)と最寄りの駅の路線 (`Line`)でグループ化することも可能です。それでは`Pref`と`Line`でグループ化し、店舗数と口コミ数、評価の平均値を計算し、ソートの順番は店舗数、店舗数が同じなら評価の平均値が高い順にしましょう。今回も`summarise()`内に`.group = "drop"`を指定し、グループ化を解除します。今回はTop 20まで出してみましょう。

```{r, attr.source='.numberLines'}
# ScoreNとScoreの平均値をPrefごとに求める
df %>%
  filter(!is.na(Line)) %>% # Lineが欠損していないケースのみ残す
  group_by(Pref, Line) %>% # PrefとLineでグループ化
  summarise(N           = n(),
            ScoreN_Sum  = sum(ScoreN,  na.rm = TRUE),
            Score_Mean  = mean(Score,  na.rm = TRUE),
            .groups     = "drop") %>%
  arrange(desc(N), desc(Score_Mean)) %>%
  print(n = 20)
```

ぐるなびに登録されているラーメン屋が最も多い路線は埼玉県内の東武東上線で122店舗があります。東武東上線は東京都と埼玉県をまたがる路線ですので、東武東上線だけならもっと多いかも知れませんね。

ここで一つ考えたいのは`summarise()`内の`.groups`引数です。前回はグループ化に使った変数ごとに1行しか残っていなかったのでグループ化を全て解除しました。しかし、今回は状況がやや異なります。グループ化変数に使った`Pref`を考えると、まだ`Pref == "東京都"`であるケースがいくつかあります。やろうとすればまだグループ化出来る状態です。これは`Line`についても同じです。`Line == "東武東上線"`の行はここには表示されていないものの、まだデータに残っています。もし、これ以上グループ化しないなら今のように`.groups = "drop"`が正しいですが、もしもう一回グループ化したい場合はどうすればよいでしょうか。方法は2つ考えられます。

1. もう一度パイプ演算子を使って`group_by()`関数を使う (以下の9行目)。
    * 結果を見ると`## # Groups:   Pref, Line [523]`で、ちゃんとグループ化されていることが分かります。

```{r, attr.source='.numberLines'}
df %>%
  filter(!is.na(Line)) %>% 
  group_by(Pref, Line) %>% 
  summarise(N           = n(),
            ScoreN_Sum  = sum(ScoreN,  na.rm = TRUE),
            Score_Mean  = mean(Score,  na.rm = TRUE),
            .groups     = "drop") %>%
  arrange(desc(N), desc(Score_Mean)) %>%
  group_by(Pref, Line) %>% # group_by()、もう一度
  print(n = 5)
```

2. `.groups`引数を何とかする。

推奨される方法は2番です。具体的には`.groups = "keep"`を指定するだけであり、こっちの方が無駄なコードを省けることができます。

```{r, attr.source='.numberLines'}
df %>%
  filter(!is.na(Line)) %>% 
  group_by(Pref, Line) %>% 
  summarise(N           = n(),
            ScoreN_Sum  = sum(ScoreN,  na.rm = TRUE),
            Score_Mean  = mean(Score,  na.rm = TRUE),
            .groups     = "keep") %>%
  arrange(desc(N), desc(Score_Mean)) %>%
  print(n = 5)
```

`.groups`引数は`"drop"`と`"keep"`以外にも`"drop_last"`があります。実は`summarise()`に`.groups`引数を指定したい場合のデフォルト値は`.groups == "drop_last"`または`"keep"`ですが、ここがややこしいです。主なケースにおいてデフォルト値は`"drop"`となりますとなります。`.groups == "drop_last"`これは最後のグループ化変数のみ解除する意味です。今回の例だと、2番目のグループ化変数である`Line`がグループ化変数から外され、`Pref`のみがグループ化変数として残る仕組みです。

それではデフォルト値が`"keep"`になるのはいつでしょうか。それは記述統計量の結果が長さ2以上のベクトルである場合です。平均値を求める`mean()`、標準偏差を求める`sd()`などは、結果として長さ1のベクトルを返します。しかし、長さ2以上ののベクトルを返す関数もあります。たとえば、分位数を求める`quantile()`関数があります。`quantile(ベクトル名, 0.25)`の場合、第一四分位点のみ返すため、結果は長さ1のベクトルです。しかし、`quantile(ベクトル名, c(0.25, 0.5, 0.75))`のように第一四分位点から第三四分位点を同時に計算し、長さ3のベクトルが返されるケースもありますし、第二引数を省略すると、最小値・第一四分位点・第二四分位点・第三四分位点・最大値、つまり、長さ5のベクトルが返される場合があります。

```{r, attr.source='.numberLines'}
# 第一四分位点のみを求める (長さ1のベクトル)
quantile(df$Walk, 0.25, na.rm = TRUE)

# 引数を省略する (長さ5のベクトル)
quantile(df$Walk, na.rm = TRUE)
```

`.groups`のデフォルト値が`"keep"`になるのは、このように長さ2以上のベクトルが返されるケースです。たとえば、都府県と最寄りの駅の路線でグループ化し、店舗までの徒歩距離の平均値を求めるとします。デフォルト値の変化を見るために、ここではあえて`.groups`引数を省略しました。

```{r, attr.source='.numberLines'}
df %>%
  filter(!is.na(Walk)) %>%
  group_by(Pref, Line) %>%
  summarise(Mean = mean(Walk))
```

最初は`Pref`と`Line`でグループ化しましたが、`summarise()`の後、`Line`がグループ化変数から外されました。つまり、引数が`"drop_last"`になっていることです。

それでは、平均値に加えて、第一四分位点と第三四分位点も計算し、`Quantile`という名で格納してみましょう。

```{r, attr.source='.numberLines'}
df %>%
  filter(!is.na(Walk)) %>%
  group_by(Pref, Line) %>%
  summarise(Mean     = mean(Walk),
            Quantile = quantile(Walk, c(0.25, 0.75)))
```

同じ`Pref`、`Line`のケースが2つずつ出来ています。最初に来る数値は第一四分位点、次に来るのが第三四分位点です。そして最初のグループ化変数であった`Pref`と`Line`が、`summarise()`後もグループ化変数として残っていることが分かります。

`.groups`引数は記述統計量だけを計算する意味ではあまり意識する必要がありません。しかし、得られた記述統計量から何らかの計算をしたり、さらにもう一回記述統計量を求めたりする際、予期せぬ結果が得られる可能性があるため注意する必要があります。出来る限り`.groups`引数は指定するようにしましょう。

---

## 変数の計算

### `mutate()`関数の使い方

続いて、データフレーム (または、tibble)内の変数を用いて計算を行い、その結果を新しい列として格納する`mutate()`関数について紹介します。まず、`mutate()`関数の書き方からです。

```{r, attr.source='.numberLines', eval = FALSE}
# mutate()関数の使い方
データフレーム/tibble名 %>%
  mutate(新しい変数名 = 処理内容)
```

これは何らかの処理を行い、その結果を新しい変数としてデータフレーム (または、tibble)に追加することを意味します。新しく出来た変数は、基本的に最後の列になります。ここでは分単位である`Walk`を時間単位に変換した`Walk_Hour`変数を作成するとします。処理内容は`Walk / 60`です。最後に、都府県名、店舗名、徒歩距離 (分)、徒歩距離 (時間)のみを残し、遠い順にソートします。

```{r, attr.source='.numberLines'}
df %>%
  filter(!is.na(Walk)) %>%
  mutate(Walk_Hour = Walk / 60) %>%
  select(Pref, Name, Walk, Walk_Hour) %>%
  arrange(desc(Walk_Hour))
```

`mutate()`は3行目に登場しますが、これは`Walk`を60に割った結果を`Walk_Hour`としてデータフレーム (または、tibble)の最後の列として格納することを意味します。もし、最後の列でなく、ある変数の前、または後にしたい場合は、`.before`または`.after`引数を追加します。これは`select()`関数の`.before`と`.after`と同じ使い方です。たとえば、新しく出来た`Walk_Hour`を`ID`と`Name`の間に入れたい場合は

```{r, attr.source='.numberLines', eval = FALSE}
# コードの3行名を修正 (.before使用)
mutate(Walk_Hour = Walk / 60,
       .before   = Name)

# コードの3行名を修正 (.after使用)
mutate(Walk_Hour = Walk / 60,
       .after    = ID)
```

のようにコードを修正します。

むろん、変数間同士の計算も可能です。たとえば、以下のような`df2`があり、1店舗当たりの平均口コミ数を計算し、`ScoreN_Mean`という変数名で`ScoreN_Sum`の後に格納うするとします。この場合、`ScoreN_Sum`変数を`N`で割るだけです。

```{r, attr.source='.numberLines'}
df2 <- df %>%
  group_by(Pref) %>%
  summarise(Budget_Mean = mean(Budget, na.rm = TRUE),
            ScoreN_Sum  = sum(ScoreN, na.rm = TRUE),
            Score_Mean  = mean(Score, na.rm = TRUE),
            N           = n(),
            .groups     = "drop")
```

```{r, attr.source='.numberLines'}
df2 %>%
  mutate(ScoreN_Mean = ScoreN_Sum / N,
         .after      = ScoreN_Sum)
```

このように、データ内の変数を用いた計算結果を新しい列として追加する場合は、`mutate()`が便利です。これを`mutate()`を使わずに処理する場合、以下のようなコードになりますが、可読性が相対的に低いことが分かります。

```{r, attr.source='.numberLines', eval = FALSE}
df2$ScoreN_Mean <- df2$ScoreN_Sum / df2$N
df2 <- df2[, c("Pref", "Budget_Mean", "Walk_Mean", 
               "ScoreN_Sum", "ScoreN_Mean", "Score_Mean", "N")]
```

むろんですが、計算には`+`や`/`のような演算子だけでなく、関数を使うことも可能です。たとえば、`Budget`が1000円未満なら`"Cheap"`、1000円以上なら`"Expensive"`と示す変数`Budget2`を作成する場合は`ifelse()`関数が使えます。

```{r, attr.source='.numberLines'}
df %>% 
  mutate(Budget2 = ifelse(Budget < 1000, "Cheap", "Expensive")) %>%
  filter(!is.na(Budget2)) %>% # Budget2が欠損した店舗を除外
  group_by(Pref, Budget2) %>% # PrefとBudget2でグループ化
  summarise(N = n(),          # 店舗数を表示
            .groups = "drop")
```

これは各都府県ごとの予算1000円未満の店と以上の店の店舗数をまとめた表となります。もし、500円未満なら`"Cheap"`、500円以上~1000円未満なら`"Reasonable"`、1000円以上なら`"Expensive"`になる`Budget3`変数を作るにはどうすればよいでしょうか。これは`ifelse()`を重ねることも出来ますが、ここでは`case_when()`関数が便利です。まずは、`ifelse()`を使ったコードは以下の通りです。

```{r, attr.source='.numberLines', eval = FALSE}
# ifelse()を使う場合
df %>% 
  mutate(Budget3 = ifelse(Budget < 500, "Cheap", 
                          ifelse(Budget >= 500 & Budget < 1000, "Reasonable",
                                 "Expensive"))) %>%
  filter(!is.na(Budget3)) %>%
  group_by(Pref, Budget3) %>%
  summarise(N = n(),         
            .groups = "drop")
```

`case_when()`を使うと以下のような書き方になります。

```{r, attr.source='.numberLines', eval = FALSE}
# ifelse()を使う場合
df %>% 
  mutate(Budget3 = case_when(Budget < 500                  ~ "Cheap",
                             Budget >= 500 & Budget < 1000 ~ "Reasonable",
                             Budget >= 1000                ~ "Expensive"),
         # 新しく出来た変数をfactor型にその場で変換することも可能
         Budget3 = factor(Budget3, 
                          levels = c("Cheap", "Reasonable", "Expensive"))) %>%
  filter(!is.na(Budget3)) %>%
  group_by(Pref, Budget3) %>%
  summarise(N = n(),         
            .groups = "drop")
```

書く手間の観点では`case_when()`は`ifelse()`と大きく違いはないかも知れませんが、コードが非常に読みやすくなっています。`case_when()`関数の書き方は以下の通りです。

```{r, attr.source='.numberLines', eval = FALSE}
# case_when()の使い方
データフレーム/tibble名 %>%
  mutate(新変数名 = case_when(条件1 ~ 条件1を満たす場合の結果値, 
                             条件2 ~ 条件2を満たす場合の結果値, 
                             条件3 ~ 条件3を満たす場合の結果値, 
                             ...))
```

似たような機能をする関数として`recode()`関数があります。これは変数の値を単純に置換したい場合に便利な関数です。たとえば、都府県名をローマ字に変換するケースを考えてみましょう。

```{r, attr.source='.numberLines'}
# recode()を使う場合
df2 %>% 
  mutate(Pref2 = recode(Pref,
                        "東京都"   = "Tokyo",
                        "神奈川県" = "Kanagawa",
                        "千葉県"   = "Chiba",
                        "埼玉県"   = "Saitama",
                        "大阪府"   = "Osaka",
                        "京都府"   = "Kyoto",
                        "兵庫県"   = "Hyogo",
                        "奈良県"   = "Nara",
                        "和歌山県" = "Wakayama",
                        .default  = "NA"))
```

使い方は非常に直感的です。

```{r, attr.source='.numberLines', eval = FALSE}
# recode()の使い方
データフレーム/tibble名 %>%
  mutate(新変数名 = recode(元の変数名,
                            元の値1 =  新しい値1, 
                            元の値2 =  新しい値2, 
                            元の値3 =  新しい値3, 
                            ...,
                            .default = 該当しない場合の値))
```

最後の`.default`引数は、もし該当する値がない場合に返す値を意味し、長さ1のベクトルを指定します。もし、指定しない場合は`NA`が表示されます。また、ここには紹介しておりませんでしたが、`.missing`引数もあり、これは欠損値の場合に返す値を意味します。

もう一つ注意すべきところは、今回はcharacter型変数をcharacter型へ変換したため、「`"東京都" = "Tokyo"`」のような書き方をしました。しかし、numeric型からcharacter型に変換する場合は数字の部分を`` ` ``で囲む必要があります。たとえば、「`` `1` = "Tokyo"``」といった形式です。ただし、character型からnumeric型への場合は「`"東京都" = 1`」で構いません。

`recode()`は値をまとめる際にも便利です。たとえば、`EastJapan`という変数を作成し、関東なら`1`を、それ以外なら`0`を付けるとします。そして、これは`Pref`変数の後に位置づけます。

```{r, attr.source='.numberLines'}
# 都府県を関東か否かでまとめる
df2 %>% 
  mutate(EastJapan = recode(Pref,
                            "東京都"   = 1,
                            "神奈川県" = 1,
                            "千葉県"   = 1,
                            "埼玉県"   = 1,
                            "大阪府"   = 0,
                            "京都府"   = 0,
                            "兵庫県"   = 0,
                            "奈良県"   = 0,
                            "和歌山県" = 0,
                            .default  = 0),
         .after = Pref)
```

ただし、関東以外は全て0になるため、以下のように省略することも可能です。

```{r, attr.source='.numberLines'}
# .default引数を指定する場合
df3 <- df2 %>% 
  mutate(EastJapan = recode(Pref,
                            "東京都"   = 1,
                            "神奈川県" = 1,
                            "千葉県"   = 1,
                            "埼玉県"   = 1,
                            .default  = 0),
         .after = Pref)

df3
```

新しく出来た`EastJapan`のデータ型はなんでしょうか。

```{r, attr.source='.numberLines'}
class(df3$EastJapan)
```

`EastJapan`はnumeric型ですね。もし、これをfactor型にしたい場合はどうすればよいでしょうか。それは`mutate()`内で`EastJapan`を生成した後に`factor()`関数を使うだけです。

```{r, attr.source='.numberLines'}
# EastJapan変数をfactor型にする
df3 <- df2 %>% 
  mutate(EastJapan = recode(Pref,
                            "東京都"   = 1,
                            "神奈川県" = 1,
                            "千葉県"   = 1,
                            "埼玉県"   = 1,
                            .default  = 0),
         EastJapan = factor(EastJapan, levels = c(0, 1)),
         .after = Pref)

df3$EastJapan
```

`EastJapan`がfactor型になりました。実は、`recode`は再コーディングと同時にfactor化をしてくれる機能があります。ただし、`recode()`関数でなく、`recode_factor()`関数を使います。

```{r, attr.source='.numberLines'}
# recode_factor()を使う方法
df3 <- df2 %>% 
  mutate(EastJapan = recode_factor(Pref,
                                   "東京都"   = 1,
                                   "神奈川県" = 1,
                                   "千葉県"   = 1,
                                   "埼玉県"   = 1,
                                   .default  = 0),
         .after = Pref)

df3$EastJapan
```

ただし、levelの順番は`recode_factor()`内で定義された順番になることに注意してください。

### factor型の処理に便利な関数

---

## 行単位の操作

ここでは行単位の操作について考えたいと思います。`select()`の説明で使った`myDF1`を見てみましょう。

```{r, attr.source='.numberLines'}
myDF1
```

ここで`X1`と`X2`と`X3`の平均値を計算し、`X_Mean`という名の変数にする場合、以下のような書き方が普通でしょう。

```{r, attr.source='.numberLines'}
myDF1 %>%
  mutate(X_Mean = mean(c(X1, X2, X3)))
```

あら、なんかおかしくありませんか。1行目の場合、`X1`と`X2`、`X3`それぞれ2、5、3であり、平均値は3.333であるはずなのに3.133になりました。これは2行目以降も同じです。なぜでしょうか。

実は`dplyr`は行単位の計算が苦手です。実際、データフレーム (または、tibble)というのは既に説明したとおり、縦ベクトルを横に並べたものです。列をまたがる場合、データ型が異なる場合も多いため、そもそも使う場面も多くありません。したがって、以下のような書き方が必要でした。

```{r, attr.source='.numberLines'}
myDF1 %>%
  mutate(X_Mean = (X1 + X2 + X3) / 3)
```

先ほどの`mean(c(X1, X2, X3))`は(`X1`列と`X2`列、`X3`列)の平均値です。`X1`は長さ1のベクトルではなく、その列全体を指すものです。つまり、`mean(c(X1, X2, X3))`は`mean(c(myD1F$X1, myDF1$X2, myDF1$X3))`と同じことになります。だから全て3.133という結果が得られました。ただし、後者はベクトル同士の加減乗除になるため問題ありません。実際`c(1, 2, 3) + c(3, 5, 0)`は同じ位置の要素同士の計算になります。

ここで`mean()`関数を使う場合には全ての演算を、一行一行に分けて行う必要があります。ある一行のみに限定する場合、`mean(c(X1, X2, X3))`の`X1`などは長さ1のベクトルになるため、`(X1 + X2 + X3) / 3`と同じことになります。この「一行単位で処理を行う」ことを指定する関数が`rowwise()`関数です。これは行単位の作業を行う前に指定するだけです。

```{r, attr.source='.numberLines'}
myDF1 %>%
  rowwise() %>%
  mutate(X_Mean = mean(c(X1, X2, X3)))
```

これで問題なく行単位の処理ができるようになりました。今回は変数が3つのみだったので、これで問題ありませんが、変数が多くなると`:`や`starts_with()`、`num_range()`などを使って変数を選択したくなります。この場合は計算する関数内に`c_across()`を入れます。ここでは`X1`列から`X3D`列までの平均値を求めてみましょう。

```{r, attr.source='.numberLines'}
myDF1 %>%
  rowwise() %>%
  mutate(X_Mean = mean(X1:X3D))
```

実は`rowwise()`関数、2020年6月に公開されたdplyr 1.0.0で注目された関数ですが、昔のdplyrにも`rowwise()`関数はありました。ただし、`purrr`パッケージや`tidyr`パッケージの`nest()`関数などにより使い道がなくなりましたが、なぜか華麗に復活しました。データ分析に使うデータは基本単位は列であるため、実際に`rowwise()`が使われる場面は今の段階では多くないでしょう。また、簡単な作業なら`X1 + X2`のような演算でも対応できます。それでも、覚えておけば便利な関数であることには間違いありません。
